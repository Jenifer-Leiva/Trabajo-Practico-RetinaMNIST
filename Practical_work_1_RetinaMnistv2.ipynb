{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tATe7h4EzWLW"
      },
      "source": [
        "UNIVERSIDAD MILITAR NUEVA GRANADA\n",
        "\n",
        "PERCEPTRON MULTICAPA\n",
        "\n",
        "Jenifer Leiva  \n",
        "Astrid Melo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mmwGM0Sly6Fz"
      },
      "outputs": [],
      "source": [
        "# Carga de librerías\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CyfZ3ONZzjDs"
      },
      "outputs": [],
      "source": [
        "# Carga de módulos\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PpZ8mIrzmjt"
      },
      "source": [
        "**Dataset**\n",
        "MedMNIST dataset\n",
        "RetinaMNIST\n",
        "\n",
        "1600 imágenes\n",
        "\n",
        "Imágenes 28x28 (Tomografía macular de la retina)\n",
        "\n",
        "Labels: 4\n",
        "\n",
        " (train & test por separado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "f2d2307d",
        "outputId": "7f354a4f-19ec-4517-a890-4439a8b60227"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting medmnist\n",
            "  Downloading medmnist-3.0.2-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from medmnist) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from medmnist) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from medmnist) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from medmnist) (0.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from medmnist) (4.67.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from medmnist) (11.3.0)\n",
            "Collecting fire (from medmnist)\n",
            "  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from medmnist) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from medmnist) (0.23.0+cu126)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from fire->medmnist) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->medmnist) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->medmnist) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->medmnist) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (1.16.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (3.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->medmnist) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->medmnist) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (4.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (1.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->medmnist) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->medmnist) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->medmnist) (3.0.2)\n",
            "Downloading medmnist-3.0.2-py3-none-any.whl (25 kB)\n",
            "Downloading fire-0.7.1-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fire, medmnist\n",
            "Successfully installed fire-0.7.1 medmnist-3.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install medmnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bb93e32f",
        "outputId": "9bf7ba8a-b562-4ad9-cdea-31be527df9d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (from keras_tuner) (3.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from keras_tuner) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from keras_tuner) (2.32.4)\n",
            "Collecting kt-legacy (from keras_tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (0.17.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (0.5.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->keras_tuner) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->keras_tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->keras_tuner) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->keras_tuner) (2025.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from optree->keras->keras_tuner) (4.14.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->keras_tuner) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->keras_tuner) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras_tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras_tuner\n",
            "Successfully installed keras_tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lOzXXRw50dQ-"
      },
      "outputs": [],
      "source": [
        "# Carga de módulos\n",
        "from medmnist import RetinaMNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "myZh3H-B1V1M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71b60187-505f-4ca5-a779-4e09dfc05d7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3.29M/3.29M [00:03<00:00, 1.01MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Cargar train y test\n",
        "train_dataset = RetinaMNIST(split=\"train\", download=True)\n",
        "val_dataset   = RetinaMNIST(split=\"val\", download=True)\n",
        "test_dataset = RetinaMNIST(split=\"test\", download=True)\n",
        "\n",
        "# Convertir a arrays\n",
        "x_train = np.array([img for img, _ in train_dataset])\n",
        "y_train = np.array([label for _, label in train_dataset])\n",
        "\n",
        "x_val = np.array([img for img, _ in val_dataset])\n",
        "y_val = np.array([label for _, label in val_dataset])\n",
        "\n",
        "x_test = np.array([img for img, _ in test_dataset])\n",
        "y_test = np.array([label for _, label in test_dataset])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xWClg9dC4p2Y"
      },
      "outputs": [],
      "source": [
        "#Reshape a un tensor de 4 dimensiones: batch size, width, height, color channels\n",
        "\n",
        "x_train = x_train.reshape( (x_train.shape[0], 28, 28, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KoIAqOxA5Jlm"
      },
      "outputs": [],
      "source": [
        "# Normalizar\n",
        "x_train = x_train.astype('float32') / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKXkKVhA5Q3H",
        "outputId": "11044b76-6f05-432d-b2a3-e3378eeae269"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       ...,\n",
              "       [2],\n",
              "       [2],\n",
              "       [3]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#Labels\n",
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "P3_Whq1R-Iss"
      },
      "outputs": [],
      "source": [
        "# Representación one-hot (categorical)\n",
        "y_train = to_categorical(y_train, num_classes=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpLKtAtM5-IA"
      },
      "source": [
        "## Hiperparametros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5XVYzMKG6B_A"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "import keras_tuner as kt\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "97a2a74b"
      },
      "outputs": [],
      "source": [
        "# Normalize x_test\n",
        "x_val = x_val.astype('float32') / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "b80c624d"
      },
      "outputs": [],
      "source": [
        "#Reshape x_test to a 4-dimensional tensor: batch size, width, height, color channels\n",
        "x_val = x_val.reshape( (x_val.shape[0], 28, 28, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9474f2d8"
      },
      "outputs": [],
      "source": [
        "y_val = to_categorical(y_val, num_classes=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNwr09e5XMUP",
        "outputId": "3a2b6965-e2dd-4eb7-b44b-37a904e20237"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 90 Complete [00h 00m 11s]\n",
            "val_accuracy: 0.46666666865348816\n",
            "\n",
            "Best val_accuracy So Far: 0.625\n",
            "Total elapsed time: 00h 06m 05s\n"
          ]
        }
      ],
      "source": [
        "# Definir la función de construcción del modelo\n",
        "#modelo 1\n",
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    # Add a Flatten layer to flatten the input images\n",
        "    model.add(layers.Flatten(input_shape=(28, 28, 3)))\n",
        "\n",
        "    # Capa oculta con número de neuronas como hiperparámetro\n",
        "    model.add(layers.Dense(\n",
        "        units=hp.Int('units', min_value=32, max_value=256, step=32),\n",
        "        activation='relu'\n",
        "    ))\n",
        "    model.add(layers.Dense(5, activation='softmax')) # Changed to 5 classes based on unique labels\n",
        "\n",
        "    # Definir optimizador y learning rate como hiperparámetros\n",
        "    optimizer = hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop'])\n",
        "    learning_rate = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
        "\n",
        "    if optimizer == 'adam':\n",
        "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    elif optimizer == 'sgd':\n",
        "        optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "    else:\n",
        "        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "\n",
        "    # Compilar el modelo\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Definir el tuner\n",
        "tuner = kt.Hyperband(\n",
        "    #construir el modelo d eparametros\n",
        "    hypermodel=build_model,\n",
        "    #optimizar valor de accuracy\n",
        "    objective='val_accuracy',   # Debe ir como string\n",
        "    #numero de epocas\n",
        "    max_epochs=30,\n",
        "    #directorio para guardar resultados hiperparametros\n",
        "    directory=\"keras_tuner_dir\",\n",
        "    project_name=\"keras_tuner_demo\"\n",
        ")\n",
        "\n",
        "epochs=30;\n",
        "batch_size=32;\n",
        "\n",
        "\n",
        "tuner.search(x_train, y_train,\n",
        "             epochs=epochs,\n",
        "             validation_data=(x_val, y_val),\n",
        "            batch_size=batch_size)\n",
        "\n",
        "\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5U9pqow9hQg",
        "outputId": "96c4d64a-cfa1-4b7c-a0f4-ee632a16873e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 79 Complete [00h 00m 06s]\n",
            "val_accuracy: 0.574999988079071\n",
            "\n",
            "Best val_accuracy So Far: 0.6333333253860474\n",
            "Total elapsed time: 00h 05m 05s\n"
          ]
        }
      ],
      "source": [
        "# Definir la función de construcción del modelo\n",
        "#modelo 2\n",
        "def build_model2(hp):\n",
        "    model2 = keras.Sequential()\n",
        "\n",
        "    # Add a Flatten layer to flatten the input images\n",
        "    model2.add(layers.Flatten(input_shape=(28, 28, 3)))\n",
        "\n",
        "    # Capa oculta con número de neuronas como hiperparámetro\n",
        "    model2.add(layers.Dense(\n",
        "        units=hp.Int('units', min_value=96, max_value=256, step=32),\n",
        "        activation='relu'\n",
        "    ))\n",
        "    model2.add(layers.Dense(5, activation='softmax')) # Changed to 5 classes based on unique labels\n",
        "\n",
        "    # Definir optimizador y learning rate como hiperparámetros\n",
        "    optimizer = hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop'])\n",
        "    learning_rate = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
        "\n",
        "    if optimizer == 'adam':\n",
        "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    elif optimizer == 'sgd':\n",
        "        optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "    else:\n",
        "        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "\n",
        "    # Compilar el modelo\n",
        "    model2.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model2\n",
        "\n",
        "# Definir el tuner\n",
        "tuner = kt.Hyperband(\n",
        "    #construir el modelo d eparametros\n",
        "    hypermodel=build_model2,\n",
        "    #optimizar valor de accuracy\n",
        "    objective='val_accuracy',   # Debe ir como string\n",
        "    #numero de epocas\n",
        "    max_epochs=30,\n",
        "    #directorio para guardar resultados hiperparametros\n",
        "    directory=\"keras_tuner_dir\",\n",
        "    project_name=\"keras_tuner_demo2\"\n",
        ")\n",
        "\n",
        "epochs=30;\n",
        "batch_size=42;\n",
        "\n",
        "\n",
        "tuner.search(x_train, y_train,\n",
        "             epochs=epochs,\n",
        "             validation_data=(x_val, y_val),\n",
        "            batch_size=batch_size)\n",
        "\n",
        "\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xL2iur2p_r8Z",
        "outputId": "0c34f3e3-1298-445e-e51d-62bf2f75e527"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 75 Complete [00h 00m 07s]\n",
            "val_accuracy: 0.4833333194255829\n",
            "\n",
            "Best val_accuracy So Far: 0.6083333492279053\n",
            "Total elapsed time: 00h 05m 24s\n"
          ]
        }
      ],
      "source": [
        "# Definir la función de construcción del modelo\n",
        "#modelo 3 dropout\n",
        "def build_model3(hp):\n",
        "    model3 = keras.Sequential()\n",
        "\n",
        "    # Add a Flatten layer to flatten the input images\n",
        "    model3.add(layers.Flatten(input_shape=(28, 28, 3)))\n",
        "\n",
        "    model3.add(layers.Dropout(0.5))\n",
        "\n",
        "    # Capa oculta con número de neuronas como hiperparámetro\n",
        "    model3.add(layers.Dense(\n",
        "        units=hp.Int('units', min_value=96, max_value=256, step=32),\n",
        "        activation='relu'\n",
        "    ))\n",
        "    model3.add(layers.Dense(5, activation='softmax')) # Changed to 5 classes based on unique labels\n",
        "\n",
        "    # Definir optimizador y learning rate como hiperparámetros\n",
        "    optimizer = hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop'])\n",
        "    learning_rate = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
        "\n",
        "    if optimizer == 'adam':\n",
        "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    elif optimizer == 'sgd':\n",
        "        optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "    else:\n",
        "        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "\n",
        "    # Compilar el modelo\n",
        "    model3.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model3\n",
        "\n",
        "# Definir el tuner\n",
        "tuner = kt.Hyperband(\n",
        "    #construir el modelo d eparametros\n",
        "    hypermodel=build_model3,\n",
        "    #optimizar valor de accuracy\n",
        "    objective='val_accuracy',   # Debe ir como string\n",
        "    #numero de epocas\n",
        "    max_epochs=30,\n",
        "    #directorio para guardar resultados hiperparametros\n",
        "    directory=\"keras_tuner_dir\",\n",
        "    project_name=\"keras_tuner_demo3\"\n",
        ")\n",
        "\n",
        "epochs=30;\n",
        "batch_size=42;\n",
        "\n",
        "\n",
        "tuner.search(x_train, y_train,\n",
        "             epochs=epochs,\n",
        "             validation_data=(x_val, y_val),\n",
        "            batch_size=batch_size)\n",
        "\n",
        "\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMqaWxp3AL7a",
        "outputId": "457330d8-2984-47fb-eb2f-195d09ce2551"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 54 Complete [00h 00m 05s]\n",
            "val_accuracy: 0.10000000149011612\n",
            "\n",
            "Best val_accuracy So Far: 0.6000000238418579\n",
            "Total elapsed time: 00h 04m 15s\n"
          ]
        }
      ],
      "source": [
        "# Definir la función de construcción del modelo\n",
        "#modelo 4 weight decay\n",
        "weight_decay = 0.001;\n",
        "def build_model4(hp):\n",
        "    model4 = keras.Sequential()\n",
        "\n",
        "    # Add a Flatten layer to flatten the input images\n",
        "    model4.add(layers.Flatten(input_shape=(28, 28, 3)))\n",
        "    # Capa oculta con número de neuronas como hiperparámetro\n",
        "    model4.add(layers.Dense(\n",
        "        units=hp.Int('units', min_value=96, max_value=256, step=32),\n",
        "        activation='relu',\n",
        "        kernel_regularizer=tf.keras.regularizers.l2(weight_decay)\n",
        "    ))\n",
        "\n",
        "    model4.add(layers.Dense(\n",
        "        units=64,\n",
        "        activation='sigmoid',\n",
        "        kernel_regularizer=tf.keras.regularizers.l2(weight_decay)\n",
        "    ))\n",
        "\n",
        "    model4.add(layers.Dense(5, activation='softmax')) # Changed to 5 classes based on unique labels\n",
        "\n",
        "    # Definir optimizador y learning rate como hiperparámetros\n",
        "    optimizer = hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop'])\n",
        "    learning_rate = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
        "\n",
        "    if optimizer == 'adam':\n",
        "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    elif optimizer == 'sgd':\n",
        "        optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "    else:\n",
        "        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "\n",
        "    # Compilar el modelo\n",
        "    model4.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model4\n",
        "\n",
        "# Definir el tuner\n",
        "tuner = kt.Hyperband(\n",
        "    #construir el modelo d eparametros\n",
        "    hypermodel=build_model4,\n",
        "    #optimizar valor de accuracy\n",
        "    objective='val_accuracy',   # Debe ir como string\n",
        "    #numero de epocas\n",
        "    max_epochs=30,\n",
        "    #directorio para guardar resultados hiperparametros\n",
        "    directory=\"keras_tuner_dir\",\n",
        "    project_name=\"keras_tuner_demo4\"\n",
        ")\n",
        "\n",
        "epochs=30;\n",
        "batch_size=42;\n",
        "\n",
        "\n",
        "tuner.search(x_train, y_train,\n",
        "             epochs=epochs,\n",
        "             validation_data=(x_val, y_val),\n",
        "            batch_size=batch_size)\n",
        "\n",
        "\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62ad2fa2"
      },
      "outputs": [],
      "source": [
        "#Imprimir Hiperparámetros seleccionados\n",
        "\n",
        "print(best_hps.values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSuHbqW46cCn"
      },
      "source": [
        "# Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNbAmz6uvbjQ"
      },
      "outputs": [],
      "source": [
        "# Construir el modelo con los mejores hiperparámetros\n",
        "model = build_model4(best_hps)\n",
        "\n",
        "# Convert y_test to one-hot encoding\n",
        "y_test = to_categorical(y_test, num_classes=5)\n",
        "\n",
        "# Entrenar el modelo\n",
        "history = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=(x_val, y_val)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAuGNTozEoP3"
      },
      "outputs": [],
      "source": [
        "# No. de parámetros en una capa FC:\n",
        "# No. unidades capa entrada * No. unidades capa salida + No. unidades capa salida (bias)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VyGDSrVJNJh"
      },
      "source": [
        "# Evolución del algoritmo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xe3sJAreJPjy"
      },
      "outputs": [],
      "source": [
        "# Gráfica de pérdida\n",
        "import matplotlib.pyplot as plt\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(len(loss))\n",
        "plt.plot(epochs, loss, 'b', label='Loss entrenamiento')\n",
        "plt.plot(epochs, val_loss, 'r', label='Loss validación')\n",
        "plt.title('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "336HIrVVJXTC"
      },
      "outputs": [],
      "source": [
        "# Gráfica de Accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy'] # Changed from 'val_categorical_accuracy'\n",
        "epochs = range(len(acc))\n",
        "plt.plot(epochs, acc, 'b', label='ACC entrenamiento')\n",
        "plt.plot(epochs, val_acc, 'r', label='ACC validación')\n",
        "plt.title('ACC')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vypnUcenJ_qk"
      },
      "source": [
        "# Prueba del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "PP3NKXwWKQen",
        "outputId": "dec993f8-f00a-4baf-9063-adbe63605cae"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "index = random.randint(0, len(x_test) -1)\n",
        "image = x_test[index]\n",
        "label = y_test[index]\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1SfUVaxw31p",
        "outputId": "9fe77260-cc08-4889-8754-51f682938b6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Etiqueta real: 0\n"
          ]
        }
      ],
      "source": [
        "label_index = label.argmax()  # índice de la clase\n",
        "print(f\"Etiqueta real: {label_index}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Xvtd2dVHQAZ0"
      },
      "outputs": [],
      "source": [
        "image = (image.reshape((1, 28, 28, 3))).astype('float32') / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAAbL3-AQHXt",
        "outputId": "45eebfe2-0158-4d84-f85c-c9c6e4ebdcb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.86741275, 0.02818245, 0.06429946, 0.03309735, 0.00700798],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "model.predict(image)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q39sc8ozQVAp",
        "outputId": "8cff6c8e-7403-4815-c91a-12fc941d4888"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Prediction:  0\n"
          ]
        }
      ],
      "source": [
        "digit = np.argmax(model.predict(image)[0], axis=-1)\n",
        "print(\"Prediction: \", digit)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}